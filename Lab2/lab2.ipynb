{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境建置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST necessary for when working with external scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# 定義濾波器函數\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    db = np.sum(y**2)\n",
    "    return db\n",
    "\n",
    "def signal_frequency_band_energies(sampled_signal, frequency_bands, sampling_frequency, order=5):\n",
    "    energies = []\n",
    "    for bands in frequency_bands:\n",
    "        energies.append(butter_bandpass_filter(sampled_signal, bands[0], bands[1], sampling_frequency, order))\n",
    "    return energies\n",
    "\n",
    "def extract_windows(data, window_size):\n",
    "    windows = []\n",
    "    for i in range(0, len(data) - window_size, window_size):  # 每次跳過window_size的長度\n",
    "        window = data[i:i + window_size]\n",
    "        \n",
    "        if len(window) == window_size:  # 確保每個窗口的大小是固定的\n",
    "            windows.append(window)\n",
    "    return np.array(windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正規化完成並保存至 CSV。\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"../WESAD/\"\n",
    "\n",
    "all_processed_windows = []\n",
    "\n",
    "for i in range(2, 18):\n",
    "    if i == 12: \n",
    "        continue\n",
    "\n",
    "    subject_path = os.path.join(BASE_PATH, f'S{i}')\n",
    "    pickle_file = os.path.join(subject_path, f'S{i}.pkl')\n",
    "\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "\n",
    "        labels = data[b'label']\n",
    "        signals = data[b'signal'][b'chest']\n",
    "\n",
    "        # 只選擇 label == 1 或 label == 2 的數據\n",
    "        mask = (labels == 1) | (labels == 2)\n",
    "        labels = labels[mask]\n",
    "        signals = {k: v[mask] for k, v in signals.items()}\n",
    "\n",
    "        acc_signal = signals[b'ACC'].flatten()\n",
    "        ecg_signal = signals[b'ECG'].flatten()\n",
    "        emg_signal = signals[b'EMG'].flatten()\n",
    "        eda_signal = signals[b'EDA'].flatten()\n",
    "        resp_signal = signals[b'Resp'].flatten()\n",
    "        temp_signal = signals[b'Temp'].flatten()\n",
    "        \n",
    "        # 確保所有信號長度一致\n",
    "        min_length = min(len(acc_signal), len(ecg_signal), len(emg_signal), len(eda_signal), len(resp_signal), len(temp_signal), len(labels))\n",
    "        ecg_signal = ecg_signal[:min_length]\n",
    "        emg_signal = emg_signal[:min_length]\n",
    "        eda_signal = eda_signal[:min_length]\n",
    "        resp_signal = resp_signal[:min_length]\n",
    "        temp_signal = temp_signal[:min_length]\n",
    "        labels = labels[:min_length]\n",
    "\n",
    "        window_size = 2100\n",
    "        \n",
    "        # 獲取窗口的索引範圍\n",
    "        windows_indices = [(i, i+window_size) for i in range(0, min_length-window_size, window_size)]\n",
    "        \n",
    "        # 對每個窗口處理\n",
    "        for start_idx, end_idx in windows_indices:\n",
    "            # 提取該窗口的各信號\n",
    "            acc_window = acc_signal[start_idx:end_idx]\n",
    "            ecg_window = ecg_signal[start_idx:end_idx]\n",
    "            emg_window = emg_signal[start_idx:end_idx]\n",
    "            eda_window = eda_signal[start_idx:end_idx]\n",
    "            resp_window = resp_signal[start_idx:end_idx]\n",
    "            temp_window = temp_signal[start_idx:end_idx]\n",
    "            \n",
    "            # 獲取該窗口的主要標籤（可以使用眾數或其他方法）\n",
    "            window_labels = labels[start_idx:end_idx]\n",
    "            label_mode = stats.mode(window_labels, keepdims=True)[0][0]\n",
    "            \n",
    "            # 計算ECG的頻帶能量\n",
    "            ecg_bands = signal_frequency_band_energies(ecg_window, \n",
    "                                                      [[0.01, 0.04], [0.04, 0.15], [0.15, 0.4], [0.4, 1.0]], \n",
    "                                                      700)\n",
    "\n",
    "            # 計算各信號的統計特徵\n",
    "            def compute_features(signal_window):\n",
    "                mean = np.mean(signal_window)\n",
    "                std = np.std(signal_window)\n",
    "                return mean, std\n",
    "\n",
    "            # ACC特徵\n",
    "            acc_mean, acc_std = compute_features(acc_window)\n",
    "            # EDA特徵\n",
    "            eda_mean, eda_std = compute_features(eda_window)\n",
    "            # EMG特徵\n",
    "            emg_mean, emg_std = compute_features(emg_window)\n",
    "            # Resp特徵\n",
    "            resp_mean, resp_std = compute_features(resp_window)\n",
    "            # Temp特徵\n",
    "            temp_mean, temp_std = compute_features(temp_window)\n",
    "            \n",
    "            # 將所有特徵和標籤組合成\n",
    "            window_features = np.concatenate([ecg_bands, \n",
    "                                              [acc_mean, acc_std], \n",
    "                                              [eda_mean, eda_std], \n",
    "                                              [emg_mean, emg_std], \n",
    "                                              [resp_mean, resp_std], \n",
    "                                              [temp_mean, temp_std], \n",
    "                                              [label_mode]])\n",
    "\n",
    "            \n",
    "            all_processed_windows.append(window_features)\n",
    "\n",
    "columns = ['ECG_ULF', 'ECG_LF', 'ECG_HF', 'ECG_UHF', 'ACC_mean', 'ACC_std', \n",
    "           'EDA_mean', 'EDA_std', 'EMG_mean', 'EMG_std', 'Resp_mean', 'Resp_std', \n",
    "           'Temp_mean', 'Temp_std', 'Label']\n",
    "\n",
    "processed_data_df = pd.DataFrame(all_processed_windows, columns=columns)\n",
    "\n",
    "# 正規化所有特徵\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 提取特徵列\n",
    "features = processed_data_df.iloc[:, :-1].values  # 所有特徵列，排除標籤和受試者ID\n",
    "features_normalized = scaler.fit_transform(features)\n",
    "\n",
    "# 創建一個新的DataFrame來存儲正規化後的數據\n",
    "normalized_df = pd.DataFrame(features_normalized, columns=processed_data_df.columns[:-1])\n",
    "\n",
    "# 將正規化後的數據與標籤和受試者ID合併\n",
    "normalized_df['Label'] = processed_data_df['Label']\n",
    "\n",
    "output_file = \"../output/lab2_data.csv\"\n",
    "normalized_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../output/lab2_data.csv\")\n",
    "\n",
    "# 分開特徵和標籤\n",
    "\n",
    "X = df.drop(columns=['Label'])  # 移除標籤 (y)  \n",
    "y = df['Label'] \n",
    "\n",
    "\n",
    "# 切分訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "決策樹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化並訓練決策樹\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "model_name = \"DecisionTree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "model_name = \"KNN\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隨機森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model_name = \"RandomForest\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost 決策樹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model_name = \"Adaboost Decision Tree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線性判別分析 (LDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "model_name = \"LDA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree\n",
      "模型準確率: 0.9880\n",
      "分類報告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.9898    0.9914    0.9906      1169\n",
      "         2.0     0.9850    0.9820    0.9835       668\n",
      "\n",
      "    accuracy                         0.9880      1837\n",
      "   macro avg     0.9874    0.9867    0.9871      1837\n",
      "weighted avg     0.9880    0.9880    0.9880      1837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 預測測試集\n",
    "print(model_name)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 計算準確率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"模型準確率: {accuracy:.4f}\")\n",
    "\n",
    "# 輸出分類報告\n",
    "print(\"分類報告：\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型準確率: 0.6344\n",
      "分類報告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.7652    0.6174    0.6834      5868\n",
      "         2.0     0.4953    0.6646    0.5676      3315\n",
      "\n",
      "    accuracy                         0.6344      9183\n",
      "   macro avg     0.6302    0.6410    0.6255      9183\n",
      "weighted avg     0.6677    0.6344    0.6416      9183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "y_pred = cross_val_predict(model, X, y, cv=logo, groups=df['Subject'])\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"模型準確率: {accuracy:.4f}\")\n",
    "report = classification_report(y, y_pred, digits=4)\n",
    "print(\"分類報告：\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
