{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境建置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# TEST necessary for when working with external scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, LSTM, GRU, Bidirectional\n",
    "from tensorflow.keras.layers import TimeDistributed, Reshape, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    # 使用固定的參數\n",
    "    conv_filters = 64\n",
    "    dropout_rate = 0.2\n",
    "    lstm_units = 96\n",
    "    learning_rate = 0.0005\n",
    "    \n",
    "    # 建立模型\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # CNN部分\n",
    "    x = layers.Conv2D(filters=conv_filters, kernel_size=(1, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(1, 2))(x)\n",
    "    x = layers.Conv2D(filters=conv_filters*2, kernel_size=(1, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(1, 2))(x)\n",
    "    \n",
    "    # 重塑以便LSTM處理\n",
    "    x = layers.TimeDistributed(layers.Flatten())(x)\n",
    "    \n",
    "    # 雙向LSTM部分\n",
    "    x = layers.Bidirectional(layers.LSTM(units=lstm_units, return_sequences=True))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(units=lstm_units//2))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # 全連接層\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 編譯模型\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "數據集大小: 193039\n",
      "特徵矩陣形狀: (193039, 5)\n",
      "特徵數據前5行:\n",
      "          ecg_singal  EMG_signal  EDA_signal  Resp_signal  Temp_signal\n",
      "1472060     0.479088    0.589569    0.046691     0.617289     0.993098\n",
      "4445638     0.490501    0.588455    0.136264     0.599632     0.993648\n",
      "190439      0.498848    0.593595    0.259311     0.537945     0.991568\n",
      "16771873    0.497551    0.592571    0.249958     0.581228     0.993343\n",
      "7882752     0.515007    0.587179    0.035938     0.602479     0.994480\n",
      "特徵數量: 5\n",
      "類別數量: 2\n",
      "重塑後的數據形狀: (193039, 1, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 讀取數據\n",
    "#df = pd.read_csv(\"../WESAD/s2_data.csv\")\n",
    "df = pd.read_csv(\"../Output/lab3_data.csv\")\n",
    "df = df.sample(frac=0.01)\n",
    "print(f\"數據集大小: {len(df)}\")\n",
    "\n",
    "# 分開特徵和標籤\n",
    "X = df.drop(columns=['Label','Subject'])  # 移除標籤 (y)  \n",
    "y = df['Label'] \n",
    "print(f\"特徵矩陣形狀: {X.shape}\")\n",
    "print(\"特徵數據前5行:\")\n",
    "print(X.head())\n",
    "\n",
    "# 確定實際特徵數量\n",
    "n_features = X.shape[1]\n",
    "print(f\"特徵數量: {n_features}\")\n",
    "\n",
    "num_classes = 2\n",
    "print(f\"類別數量: {num_classes}\")\n",
    "\n",
    "# 正確的數據重塑方式 - 根據特徵結構調整\n",
    "X_reshaped = X.values.reshape(X.shape[0], 1, n_features, 1)\n",
    "input_shape = (1, n_features, 1)\n",
    "print(f\"重塑後的數據形狀: {X_reshaped.shape}\")\n",
    "\n",
    "# 標籤處理 - 將標籤調整為從0開始\n",
    "y_adjusted = y - 1  # 如果標籤是1和2，調整為0和1\n",
    "\n",
    "# 切分訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reshaped, y_adjusted, test_size=0.2, random_state=42  \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.5776 - val_accuracy: 0.7563 - val_loss: 0.4908\n",
      "Epoch 2/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.4730 - val_accuracy: 0.7886 - val_loss: 0.4587\n",
      "Epoch 3/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.4577 - val_accuracy: 0.7924 - val_loss: 0.4325\n",
      "Epoch 4/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.4464 - val_accuracy: 0.7927 - val_loss: 0.4259\n",
      "Epoch 5/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4178 - val_accuracy: 0.8406 - val_loss: 0.3899\n",
      "Epoch 6/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4011 - val_accuracy: 0.8443 - val_loss: 0.3736\n",
      "Epoch 7/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.3934 - val_accuracy: 0.8446 - val_loss: 0.3666\n",
      "Epoch 8/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3818 - val_accuracy: 0.8449 - val_loss: 0.3640\n",
      "Epoch 9/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3752 - val_accuracy: 0.8558 - val_loss: 0.3454\n",
      "Epoch 10/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.3647 - val_accuracy: 0.8495 - val_loss: 0.3501\n",
      "Epoch 11/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.3653 - val_accuracy: 0.8522 - val_loss: 0.3470\n",
      "Epoch 12/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.3594 - val_accuracy: 0.8148 - val_loss: 0.4675\n",
      "Epoch 13/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3587 - val_accuracy: 0.8402 - val_loss: 0.3598\n",
      "Epoch 14/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8506 - loss: 0.3493 - val_accuracy: 0.8532 - val_loss: 0.3363\n",
      "Epoch 15/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8551 - loss: 0.3431 - val_accuracy: 0.8634 - val_loss: 0.3130\n",
      "Epoch 16/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8512 - loss: 0.3470 - val_accuracy: 0.8613 - val_loss: 0.3234\n",
      "Epoch 17/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.3392 - val_accuracy: 0.8545 - val_loss: 0.3393\n",
      "Epoch 18/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8555 - loss: 0.3377 - val_accuracy: 0.8626 - val_loss: 0.3157\n",
      "Epoch 19/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8575 - loss: 0.3320 - val_accuracy: 0.8649 - val_loss: 0.3132\n",
      "Epoch 20/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3331 - val_accuracy: 0.8624 - val_loss: 0.3172\n",
      "Epoch 21/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.3305 - val_accuracy: 0.8682 - val_loss: 0.3148\n",
      "Epoch 22/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.3236 - val_accuracy: 0.8666 - val_loss: 0.3093\n",
      "Epoch 23/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8597 - loss: 0.3244 - val_accuracy: 0.8620 - val_loss: 0.3195\n",
      "Epoch 24/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8636 - loss: 0.3158 - val_accuracy: 0.8748 - val_loss: 0.2895\n",
      "Epoch 25/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3127 - val_accuracy: 0.8785 - val_loss: 0.2803\n",
      "Epoch 26/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.3115 - val_accuracy: 0.8810 - val_loss: 0.2821\n",
      "Epoch 27/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8669 - loss: 0.3084 - val_accuracy: 0.8832 - val_loss: 0.2756\n",
      "Epoch 28/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.3013 - val_accuracy: 0.8823 - val_loss: 0.2796\n",
      "Epoch 29/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.3008 - val_accuracy: 0.8886 - val_loss: 0.2622\n",
      "Epoch 30/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.2952 - val_accuracy: 0.8839 - val_loss: 0.2631\n",
      "Epoch 31/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.2883 - val_accuracy: 0.8838 - val_loss: 0.2765\n",
      "Epoch 32/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.2829 - val_accuracy: 0.8948 - val_loss: 0.2320\n",
      "Epoch 33/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.2811 - val_accuracy: 0.8662 - val_loss: 0.3384\n",
      "Epoch 34/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8862 - loss: 0.2596 - val_accuracy: 0.9055 - val_loss: 0.2211\n",
      "Epoch 35/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.2841 - val_accuracy: 0.8740 - val_loss: 0.2879\n",
      "Epoch 36/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.2802 - val_accuracy: 0.8892 - val_loss: 0.2653\n",
      "Epoch 37/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.2828 - val_accuracy: 0.8966 - val_loss: 0.2439\n",
      "Epoch 38/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.2856 - val_accuracy: 0.8912 - val_loss: 0.2564\n",
      "Epoch 39/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.2811 - val_accuracy: 0.8803 - val_loss: 0.2722\n",
      "Epoch 40/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.2757 - val_accuracy: 0.8862 - val_loss: 0.2611\n",
      "Epoch 41/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.2840 - val_accuracy: 0.8813 - val_loss: 0.2673\n",
      "Epoch 42/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2775 - val_accuracy: 0.8900 - val_loss: 0.2527\n",
      "Epoch 43/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.2739 - val_accuracy: 0.8922 - val_loss: 0.2438\n",
      "Epoch 44/100\n",
      "\u001b[1m4826/4826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.2687 - val_accuracy: 0.8719 - val_loss: 0.2778\n",
      "\u001b[1m1207/1207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481us/step - accuracy: 0.9086 - loss: 0.2159\n",
      "測試準確率: 0.9055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 定義早停策略\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 使用固定的參數建立模型\n",
    "model = build_model()\n",
    "\n",
    "# 訓練模型\n",
    "batch_size = 32  # 您也可以調整批次大小\n",
    "final_history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,  # 可以設置較長的訓練時間，因為有早停機制\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 評估最終模型\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'測試準確率: {test_acc:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1207/1207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 971us/step\n",
      "模型準確率: 0.9055\n",
      "分類報告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9119    0.9426    0.9270     24585\n",
      "         1.0     0.8931    0.8403    0.8659     14023\n",
      "\n",
      "    accuracy                         0.9055     38608\n",
      "   macro avg     0.9025    0.8915    0.8964     38608\n",
      "weighted avg     0.9051    0.9055    0.9048     38608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 將預測的機率轉換為類別標籤\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 計算準確率\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "print(f\"模型準確率: {accuracy:.4f}\")\n",
    "\n",
    "# 輸出分類報告\n",
    "print(\"分類報告：\")\n",
    "print(classification_report(y_test, y_pred_labels, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preimpact_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
